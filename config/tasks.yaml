kb_retrieval_task:
  description: >
    Retrieve ALL relevant information from the knowledge base for the given query: 
    "Retrieve all information about {topic}. The problem is: {problem}. The proposed solution is: {solution}."
    Focus on providing detailed, structured, and accurate responses that align with 1 Finance's past products, policies, strategies, or other relevant company information.
    Return empty if no relevant content is found, **DO NOT USE INFORMATION FROM OTHER TASKS. DO NOT MAKE UP INFORMATION.**
  expected_output: >
    A structured JSON object containing the retrieved information from the knowledge base.
  agent: kb_agent
  
web_search_task:
  description: >
    Use the following workflow to gather relevant and credible information for a given query:
    1. Start with the provided query and analyze its context:
      - Understand the query's focus, such as the topic, problem, or solution it relates to.
      - Identify domains most likely to provide high-quality, accurate information for the query context. Examples:
        - For financial tools, consider domains about compliance, taxation, or financial regulation.
        - For security or document storage solutions, consider domains related to cybersecurity, cloud storage, or data protection.
        - For lending or fintech products, consider sources covering peer-to-peer finance, lending norms, or fintech industry news.

    2. Use an LLM to refine the query and generate an optimized search string sround the problem statement and solution, market trends, competitors, and other relevant aspects:
      - Avoid using specific names, brands, or years unless explicitly necessary.
      - Use generic yet comprehensive terms (e.g., "benefits", "trends", "impact") to ensure broad coverage.
      - Assume India as the default region unless stated otherwise.

    3. Determine the most relevant domains using an LLM and the query context:
      - Select up to 3 domains from a trusted, predefined list of whitelisted sources.
      - Include an empty string in the domain list to allow for general searches alongside domain-scoped searches.

    4. Execute web searches using the web search tool for each domain:
      - Format the search as "site:domain refined_query" for domain-specific queries.
      - Use engines such as Google, Brave, DuckDuckGo, and Bing.

    5. Retrieve and curate results:
      - Extract title, URL, content snippet, and full article content (from <article> tags when available).
      - Clean and structure results for easy consumption.
      - Filter out low-value or broken pages, prioritizing high-quality content.

    6. Score and sort results:
      - Use relevance, content quality, and context alignment as scoring criteria.
      - Fetch and process article tags for the top 5 results to extract detailed content insights.
      - Include fallback notes if no results are found in trusted domains.

    7. Return a curated list of results:
      - Include a structured summary with trusted sources and general web insights.
      - Provide actionable recommendations based on findings.

  expected_output: >
    
    A detailed, multi-source research summary that includes:
    - Key insights extracted from the specified trusted websites (cite the source for each insight).
    - Any additional supporting information from general web searches, clearly distinguished from official sources.
    - A final analysis that synthesizes the findings and provides actionable insights regarding the product context, topic, problem, and solution.

    A summary should be structured into sections:
    - **Trusted Sources Insights**: Findings from official and trusted domains.
    - **General Web Insights**: Supplementary information from broader web searches.
    - **Final Analysis**: A synthesized view of all findings with actionable recommendations.

    The summary should be actionable, highlighting key takeaways and insights relevant to the query context.
    Ensure that trusted sources are prioritized and clearly distinguish between official and general insights.

  agent: web_search_agent

web_scrape_extraction_task:
  description: >
    Visit and scrape content from the given links: ```{web_scraping_links}``` using the Web Scraping Tool.
    After scraping, extract all relevant information that relates to 1 Finance's new offering—this could include details about the product, its past versions, competitor insights among other possibilities. 
    Only extract content that is present on the page; do not invent any details. **DO NOT USE INFORMATION FROM OTHER TASKS. DO NOT MAKE UP INFORMATION.**
  expected_output: >
    A structured JSON object containing all relevant extracted content from each web page. The key should be the URL and the value should be the extracted content. If no link is provided or the web page could not be scraped, the value should indicate the error or lack of content.
  agent: web_scrape_extractor

extract_info_task:
  description: >
    Carefully extract key information from the provided list of reference documents content ```{reference_doc_content}```. 
    Take a moment to understand the purpose of each document in the list, understand the relationship between them and generate content that is consistent and sensible with respect to the problem statement and the solution.
    Focus on retrieving details like Problem Statement, Solution, Objectives, Target Customers, Key Features, Limitations, Benefits, and Market Context. 
    Return empty if no relevant content is found, **DO NOT USE INFORMATION FROM OTHER TASKS. DO NOT MAKE UP INFORMATION.**
  expected_output: >
    A structured JSON object containing the extracted information ready for PR FAQ generation.
  agent: extract_info_agent

content_generation_task:
  description: >
    Generate a highly detailed and structured PR FAQ introduction on ```{topic}``` by leveraging the provided prompt, the knowledge base information received from the {chat_history}, the output of kb_retrieval_task and web search output of web_search_task.
    USE THE WEB SEARCH TOOL TO SEARCH FOR COMPETITORS WHO ARE TRYING TO SOLVE THE SAME {problem}, THE COMPANY/PRODUCT NAME AND THE COMPANY/PRODUCT URL AND SET TRUST TO FALSE.
    Follow the exact JSON template below, using placeholders for any specific dates, names, or locations:
    {{
      "Title": "1 FINANCE ANNOUNCES XXX TO ENABLE XXX TO OBTAIN/HAVE XXX.",
      "Subtitle": "The subtitle reframes the headline solution. Write one sentence about the benefits.",
      "IntroParagraph": "[Location] - [Launch Date] - 2-4 sentences that gives a summary of the product and the benefits. Should be self-contained so that a person could read only this paragraph and still understand the new product/feature.
      "ProblemStatement": "2-4 sentences describing the problems this product plans to solve and briefly describe the problem and its negative impact. This section tests your assumptions about the pain-points that you are addressing.",
      "Solution": "2-4 sentences describing how the new product addresses these problems. For more complex products, you may need more than one paragraph. This section tests your assumptions about how you are solving the pain-points.",
      "Competitors": "[{{"name": "Company name or Product name", "url":"URL of the product website"}}]" [LIST OF JSON]
    }}
  expected_output: >
    A JSON object strictly following the provided template with all required sections using information from reference document and scraped web page.
  agent: content_generation_agent

faq_generation_task:
  description: >
    Take a moment to think about all possible questions that can be asked about this offering or topic.
    Use information from {chat_history} to make any necessary updates with the latest information.
    USE THE OUTPUT OF kb_retrieval_task to answer questions. Only if the relevant information is not available from the available knowledge base information, use the generated content to answer them.
    Based on the generated PR FAQ introduction, create a comprehensive FAQ document divided into two categories:
       1.**Internal FAQs**: (17-20 questions) focusing on:
        - Business rationale and market need
        - Product vision and alignment with company strategy
        - Technical approach, risks, and scalability
        - Internal roles, stakeholders, and dependencies
        - Legal, compliance, and privacy concerns
        - Resourcing, timeline, and launch readiness
        - Success metrics and future roadmap

       2.**External FAQs**: (17-20 questions) focusing on:
        - What the product is and what problems it solves
        - Who it's for and how it's used
        - Pricing, availability, and onboarding process
        - Key features and known limitations
        - Security, privacy, and data handling
        - Support, integrations, and future updates
    
    Read the last user message in {chat_history}, accordingly make the PRFAQ or make the changes and add a field of UserResponse as a reply to what the user requested in that last message. 

    Important Prioritisation for Answering Each Question:
    - Always follow this strict order of sourcing:
    1. **First**, use relevant information from the Knowledge Base `kb_qdrant_tool` and the output of kb_retrieval_task. These should be the Primary sources for answering the question.
    2. **Second**, if no suitable answer exists in the Knowledge Base, use output of web_search_task to construct the response.
    3. **Third**, only if neither the Knowledge Base nor Web Search provides an answer, generate original content independently — ensuring strict factual accuracy, based only on verified information.

    UNDER NO CIRCUMSTANCES SHOULD FABRICATED OR ASSUMED CONTENT BE INTRODUCED. ALWAYS PRIORITISE VERIFIABLE, CREDIBLE INFORMATION.
   
    Ensure each FAQ question and answer covers a **distinct and meaningful** topic.
    - **Do not** repeat the same ideas in slightly different wording.
    - **Do not** introduce redundant, overlapping, or unnecessarily similar questions.
    - Aim for maximum breadth, depth, and non-repetition across all FAQs.

    Combine the output of content_generation_task (which includes Title, Subtitle, IntroParagraph, ProblemStatement, Solution) with the FAQs (InternalFAQs, ExternalFAQs - both in Question and Answer format into a single, properly formatted JSON object.  
    You may ask a few relevant questions based on web search results too in order the enhance the FAQs and make them more recent or specific. Avoid numbering the questions in the FAQs.
    THE QUESTIONS SHOULD BE EXHAUSTIVE AND ANSWERS SHOULD BE **EXTREMELY DETAILED**, ALL-INFORMING AND WELL-FORMATTED. Include examples, step-by-step guidance, markdown-formatted tables where applicable, and clearly marked sub-points or bullet points (using strings like "\n-") or bold or italics for clarity. 

  expected_output: >
    A complete JSON object containing the PR FAQ introduction along with two arrays—InternalFAQs and ExternalFAQs—each populated with an exhaustive list of questions and detailed, well-formatted answers using proper markdown-formatted tables, sub-points, bold or italics wherever necessary. Do not give simple one sentence answers. The JSON format should be:
    {{
      "Title": "Revolutionizing AI Assistants",
      "Subtitle": "Introducing the Next-Gen AI for Business Solutions",
      "IntroParagraph": "In today's digital age, businesses need smarter AI solutions to streamline workflows and improve efficiency. Our new AI assistant is here to revolutionize the way companies operate.",
      "ProblemStatement": "Many businesses struggle with automating repetitive tasks, improving customer support, and handling large volumes of inquiries efficiently.",
      "Solution": "Our AI assistant leverages cutting-edge NLP and machine learning to provide seamless automation, personalized responses, and real-time insights.",
      "InternalFAQs": [
          {{
              "Question": "How does the AI assistant integrate with existing tools?",
              "Answer": "It seamlessly integrates with platforms like \n-Slack \n-Microsoft Teams \n-CRM systems via APIs."
          }},
          {{
              "Question": "What kind of training data is required?",
              "Answer": "The AI assistant can be **fine-tuned** with company-specific data for enhanced performance."
          }}
      ],
      "ExternalFAQs": [
          {{
              "Question": "Is the AI assistant secure?",
              "Answer": "Yes, we use industry-standard encryption and compliance measures to ensure data security."
          }},
          {{
              "Question": "Can the AI assistant handle multiple languages?",
              "Answer": "Absolutely! It's developed in a way that supports multiple languages and can be customized based on user needs."
          }},
          {{
              "Question": "Can I use Markdown-style tables?",
              "Answer": "| Feature         | Benefit        |\n|------------------|----------------|\n| Auto-Generate    | Saves time     |\n| LLM-Driven       | Context aware  |"
          }},
          {{
              "Question": "Can I also return JSON-style tables?",
              "Answer": [
                {{"Input Type": "Markdown Table", "Support": "Yes"}},
                {{"Input Type": "JSON Table", "Support": "Yes"}}
              ]
          }}
      ],
      "UserResponse": "Here is the generated PR/FAQ document on topic and your provided inputs. Please review and let me know if any changes are needed."
    }}
    THE OUTPUT SHOULD BE STRICTLY IN JSON.
  agent: faq_generation_agent
  